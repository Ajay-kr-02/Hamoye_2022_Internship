{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-03-22T08:19:00.468132Z",
     "iopub.status.busy": "2022-03-22T08:19:00.467709Z",
     "iopub.status.idle": "2022-03-22T08:19:47.763264Z",
     "shell.execute_reply": "2022-03-22T08:19:47.762502Z",
     "shell.execute_reply.started": "2022-03-22T08:19:00.468032Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T08:19:47.766108Z",
     "iopub.status.busy": "2022-03-22T08:19:47.765900Z",
     "iopub.status.idle": "2022-03-22T08:19:53.395014Z",
     "shell.execute_reply": "2022-03-22T08:19:53.394254Z",
     "shell.execute_reply.started": "2022-03-22T08:19:47.766082Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd\n",
    "#import cv2, gc\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Flatten, InputLayer\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications import ResNet50, VGG16\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.backend import clear_session\n",
    "import tensorflow as tf\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import time\n",
    "\n",
    "from os import listdir\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T08:19:53.396611Z",
     "iopub.status.busy": "2022-03-22T08:19:53.396365Z",
     "iopub.status.idle": "2022-03-22T08:19:53.404209Z",
     "shell.execute_reply": "2022-03-22T08:19:53.403402Z",
     "shell.execute_reply.started": "2022-03-22T08:19:53.396577Z"
    }
   },
   "outputs": [],
   "source": [
    "input_size = 128\n",
    "epochs = 10\n",
    "dropout_rate = 0.5\n",
    "batch_size = 128\n",
    "shape = (input_size, input_size, 3)\n",
    "path = '../input/planets-dataset/planet/planet/'\n",
    "train_path = '../input/planets-dataset/planet/planet/train-jpg'\n",
    "test_path = '../input/planets-dataset/planet/planet/test-jpg'\n",
    "lr = 0.0001\n",
    "reg_str = 0.01 # Regularization Strength\n",
    "nfolds = 2 # No of folds for cross validation\n",
    "workers = 4 # Multithreading no of threads\n",
    "maxq = 10 # Max Queue size for multithreading\n",
    "tresh = [0.2] * 17 # Threshold for truth value of label, applied on sigmoid output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T08:19:53.409757Z",
     "iopub.status.busy": "2022-03-22T08:19:53.408929Z",
     "iopub.status.idle": "2022-03-22T08:19:53.786170Z",
     "shell.execute_reply": "2022-03-22T08:19:53.785417Z",
     "shell.execute_reply.started": "2022-03-22T08:19:53.409699Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(f'{path}train_classes.csv')\n",
    "df_test = pd.read_csv(f'{path}sample_submission.csv')\n",
    "\n",
    "df_train['image_name'] = df_train['image_name'].astype(str) + '.jpg'\n",
    "df_test['image_name'] = df_test['image_name'].astype(str) + '.jpg'\n",
    "\n",
    "df_test['tags'] = df_test['tags'].apply(lambda x: x.split(' '))\n",
    "\n",
    "print(df_train.head())\n",
    "print(df_test.head())\n",
    "\n",
    "X_train_files = np.array(df_train['image_name'].tolist())\n",
    "X_train_files.reshape((X_train_files.shape[0], 1))\n",
    "\n",
    "y_train = np.array(df_train['tags'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T08:19:53.787850Z",
     "iopub.status.busy": "2022-03-22T08:19:53.787282Z",
     "iopub.status.idle": "2022-03-22T08:19:53.829795Z",
     "shell.execute_reply": "2022-03-22T08:19:53.829087Z",
     "shell.execute_reply.started": "2022-03-22T08:19:53.787810Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = []\n",
    "\n",
    "for tag in df_train['tags'].values:\n",
    "    labels_in_tag = tag.split(' ')\n",
    "    for label in labels_in_tag:\n",
    "        if label not in labels:\n",
    "            labels.append(label)\n",
    "        \n",
    "labels.sort()\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T08:19:53.831415Z",
     "iopub.status.busy": "2022-03-22T08:19:53.831028Z",
     "iopub.status.idle": "2022-03-22T08:19:55.108076Z",
     "shell.execute_reply": "2022-03-22T08:19:55.107436Z",
     "shell.execute_reply.started": "2022-03-22T08:19:53.831379Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "res = [32, 64, 128, 256]\n",
    "NIMGS = 5\n",
    "\n",
    "for i in range(len(res)):\n",
    "    for j in range(NIMGS):\n",
    "        img = cv2.imread(os.path.join(train_path,df_train['image_name'][j+1]))\n",
    "        img = cv2.resize(img, (res[i], res[i]))\n",
    "        plt.subplot(len(res), NIMGS, i*NIMGS+j+1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(df_train['tags'][j+1] + \"\\n\" + str(res[i]) + \"x\" + str(res[i]), rotation=18)\n",
    "        plt.axis('off')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T08:19:55.109584Z",
     "iopub.status.busy": "2022-03-22T08:19:55.109254Z",
     "iopub.status.idle": "2022-03-22T08:19:59.045795Z",
     "shell.execute_reply": "2022-03-22T08:19:59.045103Z",
     "shell.execute_reply.started": "2022-03-22T08:19:55.109554Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(shape))\n",
    "    model.add(VGG16(weights='imagenet', include_top=False))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(17, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "clear_session()\n",
    "\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T08:19:59.047336Z",
     "iopub.status.busy": "2022-03-22T08:19:59.047087Z",
     "iopub.status.idle": "2022-03-22T08:19:59.056344Z",
     "shell.execute_reply": "2022-03-22T08:19:59.055558Z",
     "shell.execute_reply.started": "2022-03-22T08:19:59.047301Z"
    }
   },
   "outputs": [],
   "source": [
    "def f2_score(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, \"int32\")\n",
    "    y_pred = tf.cast(tf.round(y_pred), \"int32\") # implicit 0.5 threshold via tf.round\n",
    "    y_correct = y_true * y_pred\n",
    "    sum_true = tf.reduce_sum(y_true, axis=1)\n",
    "    sum_pred = tf.reduce_sum(y_pred, axis=1)\n",
    "    sum_correct = tf.reduce_sum(y_correct, axis=1)\n",
    "    precision = sum_correct / sum_pred\n",
    "    recall = sum_correct / sum_true\n",
    "    f_score = 5 * precision * recall / (4 * precision + recall)\n",
    "    f_score = tf.where(tf.math.is_nan(f_score), tf.zeros_like(f_score), f_score)\n",
    "    return tf.reduce_mean(f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T08:19:59.058237Z",
     "iopub.status.busy": "2022-03-22T08:19:59.057991Z",
     "iopub.status.idle": "2022-03-22T09:26:49.021103Z",
     "shell.execute_reply": "2022-03-22T09:26:49.019559Z",
     "shell.execute_reply.started": "2022-03-22T08:19:59.058202Z"
    }
   },
   "outputs": [],
   "source": [
    "num_fold = 0\n",
    "\n",
    "y_test = []\n",
    "y_test2 = []\n",
    "\n",
    "folds = KFold(n_splits=nfolds, shuffle=True, random_state=1).split(X_train_files, y_train)\n",
    "\n",
    "for train_index, val_index in folds:\n",
    "    X_train_files_fold = X_train_files[train_index]\n",
    "    y_train_fold = y_train[train_index]\n",
    "    X_val_files_fold = X_train_files[val_index]\n",
    "    y_val_fold = np.array(y_train[val_index])\n",
    "    \n",
    "    train_df = pd.DataFrame(list(zip(X_train_files_fold, y_train_fold)), columns = ['image_name', 'tags'])\n",
    "    val_df = pd.DataFrame(list(zip(X_val_files_fold, y_val_fold)), columns = ['image_name', 'tags'])\n",
    "    \n",
    "    train_df['tags'] = train_df['tags'].apply(lambda x: x.split(' '))\n",
    "    val_df['tags'] = val_df['tags'].apply(lambda x: x.split(' '))\n",
    "\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True\n",
    "    )\n",
    "    \n",
    "    train_generator = train_datagen.flow_from_dataframe(\n",
    "        train_df,\n",
    "        directory=train_path,\n",
    "        x_col='image_name',\n",
    "        y_col='tags',\n",
    "        target_size=(shape[0], shape[1]),\n",
    "        class_mode='categorical',\n",
    "        batch_size=batch_size,\n",
    "        classes=labels,\n",
    "    )\n",
    "    \n",
    "    val_datagen = ImageDataGenerator(\n",
    "        rescale=1./255\n",
    "    )\n",
    "    \n",
    "    val_generator = val_datagen.flow_from_dataframe(\n",
    "        val_df,\n",
    "        directory=train_path,\n",
    "        x_col='image_name',\n",
    "        y_col='tags',\n",
    "        target_size=(shape[0], shape[1]),\n",
    "        class_mode='categorical',\n",
    "        batch_size=batch_size,\n",
    "        classes=labels,\n",
    "    )\n",
    "    \n",
    "    test_datagen = ImageDataGenerator(\n",
    "        rescale=1./255\n",
    "    )\n",
    "    \n",
    "    test_generator = test_datagen.flow_from_dataframe(\n",
    "        df_test,\n",
    "        directory=test_path,\n",
    "        x_col='image_name',\n",
    "        y_col='tags',\n",
    "        target_size=(shape[0], shape[1]),\n",
    "        class_mode='categorical',\n",
    "        batch_size=batch_size,\n",
    "        classes=labels,\n",
    "        shuffle=False,\n",
    "    )\n",
    "    \n",
    "    test_datagen2 = ImageDataGenerator(\n",
    "        rescale=1./255\n",
    "    )\n",
    "    \n",
    "    test_generator2 = test_datagen2.flow_from_dataframe(\n",
    "        df_test,\n",
    "        directory=\"../input/planets-dataset/test-jpg-additional/test-jpg-additional\",\n",
    "        x_col='image_name',\n",
    "        y_col='tags',\n",
    "        target_size=(shape[0], shape[1]),\n",
    "        class_mode='categorical',\n",
    "        batch_size=batch_size,\n",
    "        classes=labels,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "\n",
    "    model_path_of_fold = os.path.join('', 'weights_of_fold_' + str(num_fold) + '.h5')\n",
    "    \n",
    "    clear_session()\n",
    "    model = create_model()\n",
    "    \n",
    "    adam = Adam(learning_rate=lr)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=[f2_score])\n",
    "    \n",
    "    callbacks = [\n",
    "        ModelCheckpoint(model_path_of_fold, monitor='val_f2_score', save_best_only=True, mode='max'),\n",
    "        ReduceLROnPlateau(monitor='loss', factor=0.1, patience=3, mode='min', min_lr=0.000001)\n",
    "    ]\n",
    "    \n",
    "    model.fit_generator(train_generator, epochs=epochs, validation_data=val_generator, callbacks=callbacks,\n",
    "                       workers=workers, use_multiprocessing=True, max_queue_size=maxq)\n",
    "\n",
    "    model.load_weights(model_path_of_fold)\n",
    "\n",
    "    p_test = model.predict_generator(test_generator, workers=workers, use_multiprocessing=True, max_queue_size=maxq)\n",
    "    y_test.append(p_test)\n",
    "    \n",
    "    p_test2 = model.predict_generator(test_generator2, workers=workers, use_multiprocessing=True, max_queue_size=maxq)\n",
    "    y_test2.append(p_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T09:26:49.027746Z",
     "iopub.status.busy": "2022-03-22T09:26:49.027428Z",
     "iopub.status.idle": "2022-03-22T09:26:49.071634Z",
     "shell.execute_reply": "2022-03-22T09:26:49.070825Z",
     "shell.execute_reply.started": "2022-03-22T09:26:49.027688Z"
    }
   },
   "outputs": [],
   "source": [
    "result1 = np.array(y_test[0])\n",
    "for i in range(1, nfolds):\n",
    "    result1 += np.array(y_test[i])\n",
    "result1 /= nfolds\n",
    "result1 = pd.DataFrame(result1, columns = labels)\n",
    "result1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T09:26:49.073526Z",
     "iopub.status.busy": "2022-03-22T09:26:49.072902Z",
     "iopub.status.idle": "2022-03-22T09:26:49.105978Z",
     "shell.execute_reply": "2022-03-22T09:26:49.105243Z",
     "shell.execute_reply.started": "2022-03-22T09:26:49.073480Z"
    }
   },
   "outputs": [],
   "source": [
    "result2 = np.array(y_test2[0])\n",
    "for i in range(1, nfolds):\n",
    "    result2 += np.array(y_test2[i])\n",
    "result2 /= nfolds\n",
    "result2 = pd.DataFrame(result2, columns = labels)\n",
    "result2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T09:26:49.108885Z",
     "iopub.status.busy": "2022-03-22T09:26:49.107573Z",
     "iopub.status.idle": "2022-03-22T09:26:49.128167Z",
     "shell.execute_reply": "2022-03-22T09:26:49.127547Z",
     "shell.execute_reply.started": "2022-03-22T09:26:49.108836Z"
    }
   },
   "outputs": [],
   "source": [
    "results = result1.append(result2, ignore_index=True)\n",
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T09:26:49.143583Z",
     "iopub.status.busy": "2022-03-22T09:26:49.141506Z",
     "iopub.status.idle": "2022-03-22T09:28:18.147670Z",
     "shell.execute_reply": "2022-03-22T09:28:18.146747Z",
     "shell.execute_reply.started": "2022-03-22T09:26:49.143541Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for i in range(results.shape[0]):\n",
    "    a = results.iloc[[i]]\n",
    "    a = a.apply(lambda x: x > tresh, axis=1)\n",
    "    a = a.transpose()\n",
    "    a = a.loc[a[i] == True]\n",
    "    ' '.join(list(a.index))\n",
    "    predictions.append(' '.join(list(a.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T09:28:18.149151Z",
     "iopub.status.busy": "2022-03-22T09:28:18.148891Z",
     "iopub.status.idle": "2022-03-22T09:28:18.194105Z",
     "shell.execute_reply": "2022-03-22T09:28:18.193423Z",
     "shell.execute_reply.started": "2022-03-22T09:28:18.149116Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test['image_name'] = df_test['image_name'].astype(str).str.slice(stop=-4)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T09:28:18.195807Z",
     "iopub.status.busy": "2022-03-22T09:28:18.195384Z",
     "iopub.status.idle": "2022-03-22T09:28:18.223339Z",
     "shell.execute_reply": "2022-03-22T09:28:18.222684Z",
     "shell.execute_reply.started": "2022-03-22T09:28:18.195768Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df_test['tags'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T09:28:18.225157Z",
     "iopub.status.busy": "2022-03-22T09:28:18.224666Z",
     "iopub.status.idle": "2022-03-22T09:28:18.235246Z",
     "shell.execute_reply": "2022-03-22T09:28:18.234583Z",
     "shell.execute_reply.started": "2022-03-22T09:28:18.225121Z"
    }
   },
   "outputs": [],
   "source": [
    "fin = pd.DataFrame(df_test[\"image_name\"])\n",
    "fin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T09:28:18.237100Z",
     "iopub.status.busy": "2022-03-22T09:28:18.236603Z",
     "iopub.status.idle": "2022-03-22T09:28:18.253604Z",
     "shell.execute_reply": "2022-03-22T09:28:18.252963Z",
     "shell.execute_reply.started": "2022-03-22T09:28:18.237063Z"
    }
   },
   "outputs": [],
   "source": [
    "fin[\"tags\"] = predictions\n",
    "fin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T09:28:18.255404Z",
     "iopub.status.busy": "2022-03-22T09:28:18.254945Z",
     "iopub.status.idle": "2022-03-22T09:28:18.429910Z",
     "shell.execute_reply": "2022-03-22T09:28:18.429153Z",
     "shell.execute_reply.started": "2022-03-22T09:28:18.255369Z"
    }
   },
   "outputs": [],
   "source": [
    "fin.to_csv('class_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
